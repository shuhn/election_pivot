{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from name_dict import parse_names, file_grab\n",
    "import re\n",
    "import numpy as np\n",
    "import itertools\n",
    "import string\n",
    "import operator\n",
    "from textblob import TextBlob\n",
    "from summa import summarizer\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import OrderedDict\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict1 = {\"H\": [\"I said this today.\"], \"D\": [\"I am TRUMP.\"]}\n",
    "dict2 = {\"H\": [\"I said this yesterday.\"], \"D\": [\"I am DRUMF.\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "relevant_debates = [dict1, dict2]\n",
    "aggregate_dict = {}\n",
    "for d in relevant_debates:\n",
    "    for k, v in d.iteritems():\n",
    "        if aggregate_dict.has_key(k):\n",
    "            aggregate_dict[k] = aggregate_dict[k] + v\n",
    "        else:\n",
    "            aggregate_dict[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'D': ['I am TRUMP.', 'I am DRUMF.'],\n",
       " 'H': ['I said this today.', 'I said this yesterday.']}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blob = TextBlob('Hi my name is Scotty. I am DS.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi my name is Scotty.\n",
      "I am DS.\n"
     ]
    }
   ],
   "source": [
    "for sentence in blob.sentences:\n",
    "    print sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def setup_agg_df(relevant_debates, defaults = ['H', 'D']):\n",
    "    #aggregate dictionaries\n",
    "    aggregate_dict = {}\n",
    "    for d in relevant_debates:\n",
    "        for k, v in d.iteritems():\n",
    "            if aggregate_dict.has_key(k):\n",
    "                aggregate_dict[k] = aggregate_dict[k] + v\n",
    "            else:\n",
    "                aggregate_dict[k] = v\n",
    "\n",
    "    #setup df - column = candidate name, rows = sentences\n",
    "    df_list = []\n",
    "    column_list = []\n",
    "    flag = False\n",
    "    for candidate in defaults:\n",
    "        sentence_list = []\n",
    "        list_words = aggregate_dict[candidate]\n",
    "        string_words = (' '.join(list_words))\n",
    "        textblob = TextBlob(string_words)\n",
    "        for sentence in textblob.sentences:\n",
    "            sentence_list.append(str(sentence))\n",
    "        if flag == False: \n",
    "            df = pd.DataFrame(sentence_list, columns = [candidate])\n",
    "            flag = True\n",
    "        else: \n",
    "            df[candidate] = sentence_list\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>H</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I said this today.</td>\n",
       "      <td>I am TRUMP.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I said this yesterday.</td>\n",
       "      <td>I am DRUMF.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        H            D\n",
       "0      I said this today.  I am TRUMP.\n",
       "1  I said this yesterday.  I am DRUMF."
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_modeling(relevant_debates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<WordListCorpusReader in u'/Users/scotthuhn/nltk_data/corpora/stopwords'>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    regex = re.compile('<.+?>|[^a-zA-Z]')\n",
    "    clean_txt = regex.sub(' ', text)\n",
    "    tokens = clean_txt.split()\n",
    "    lowercased = [t.lower() for t in tokens]\n",
    "    no_stopwords = [w for w in lowercased if not w in stopwords.words('english')]\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    lemmed = [wordnet_lemmatizer.lemmatize(w) for w in no_stopwords]\n",
    "    return [w for w in lemmed if w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "line = \"this is a line of text starting here.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'line text starting'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(tokenize(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"probability\": {\"neg\": 0.22531846855219551, \"neutral\": 0.084284385065714951, \"pos\": 0.77468153144780449}, \"label\": \"pos\"}\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "data = urllib.urlencode({\"text\": \"I'm a very good boy \"}) \n",
    "u = urllib.urlopen(\"http://text-processing.com/api/sentiment/\", data)\n",
    "the_page = u.read()\n",
    "print the_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "items = the_page.split(':')\n",
    "imp_items = items[2:4]\n",
    "output_list = []\n",
    "for string1 in imp_items: \n",
    "    output_list.append(float(string1.split(',')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2253184685521955, 0.08428438506571495]\n"
     ]
    }
   ],
   "source": [
    "print output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict1 = {1 : 'hi', 3 : 'hello', 4 : 'mr.', 2 : 'you'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_5 = OrderedDict(sorted(dict1.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([(1, 'hi'), (2, 'you'), (3, 'hello'), (4, 'mr.')])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 hi\n",
      "2 you\n",
      "3 hello\n"
     ]
    }
   ],
   "source": [
    "x = 0\n",
    "for key, value in top_5.iteritems():\n",
    "    if x < 3:\n",
    "        print key, value\n",
    "    x += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'hello'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-b89d2da59ec1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hello'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'hello'"
     ]
    }
   ],
   "source": [
    "int('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
